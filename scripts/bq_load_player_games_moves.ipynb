{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Query executed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas_gbq import read_gbq\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up BigQuery client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../keyfile.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the BigQuery dataset and table names\n",
    "dataset_id = 'chesscom-451104.staging'\n",
    "table_games = f'{dataset_id}.games_infos_*'\n",
    "table_games_prefix = 'games_moves_'  # Prefix for wildcard tables\n",
    "\n",
    "# Check if at least one table with the prefix \"games_moves_\" exists\n",
    "def table_with_prefix_exists(client, dataset_id, prefix):\n",
    "    tables = client.list_tables(dataset_id)  # List all tables in the dataset\n",
    "    return any(table.table_id.startswith(prefix) for table in tables)\n",
    "\n",
    "# Check if games_moves_* tables exist\n",
    "if table_with_prefix_exists(client, dataset_id, table_games_prefix):\n",
    "    # Define SQL query to get games not yet processed using wildcard tables\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{table_games}` game\n",
    "    LEFT OUTER JOIN (SELECT DISTINCT game_uuid FROM `{dataset_id}.games_moves_*`) games_moves\n",
    "    USING (game_uuid)\n",
    "    WHERE games_moves.game_uuid IS NULL\n",
    "    \"\"\"\n",
    "else:\n",
    "    # If no games_moves_* table exists, select all games\n",
    "    query = f\"SELECT * FROM `{table_games}`\"\n",
    "\n",
    "# Run the query and load the result into a DataFrame\n",
    "games = read_gbq(query, project_id='chesscom-451104', dialect='standard')\n",
    "\n",
    "print(\"Query executed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b14804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the data volume (to be deleted once in production)\n",
    "# games = games[games['username'].isin(['piwi100', 'Zundorn', 'leprechess','bgdu33'])].copy()\n",
    "# games = games.sort_values(by='end_time', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 games\n",
      "Processed 2 games\n",
      "Processed 3 games\n",
      "Processed 4 games\n",
      "Processed 5 games\n",
      "Processed 6 games\n",
      "Processed 7 games\n"
     ]
    }
   ],
   "source": [
    "import chess.pgn\n",
    "import chess.engine\n",
    "import io\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to Stockfish\n",
    "engine_path = \"C:/Program Files/ChessEngines/stockfish_16/stockfish-windows-x86-64-avx2.exe\"\n",
    "\n",
    "if __name__ == \"__main__\" and hasattr(asyncio, 'WindowsProactorEventLoopPolicy'):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "def analyze_chess_game(game_uuid: str, pgn: str, engine_path: str):\n",
    "    # Load the PGN\n",
    "    game = chess.pgn.read_game(io.StringIO(pgn))\n",
    "\n",
    "    # Initialize lists to hold data\n",
    "    move_numbers = []\n",
    "    moves = []\n",
    "    scores_white = []\n",
    "\n",
    "    # Analyze the game\n",
    "    with chess.engine.SimpleEngine.popen_uci(engine_path) as engine:\n",
    "        board = game.board()\n",
    "\n",
    "        for i, move in enumerate(game.mainline_moves(), 1):\n",
    "            board.push(move)\n",
    "            info = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
    "            score_white = info[\"score\"].white().score(mate_score=1000)\n",
    "\n",
    "            # Append data to lists\n",
    "            move_numbers.append(i)\n",
    "            moves.append(move.uci())\n",
    "            scores_white.append(score_white)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"game_uuid\": [game_uuid] * len(move_numbers),\n",
    "        \"move_number\": move_numbers,\n",
    "        \"move\": moves,\n",
    "        \"score_white\": scores_white\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def analyze_multiple_games(games: pd.DataFrame, engine_path: str):\n",
    "    # Initialize an empty list to store individual game dataframes\n",
    "    game_dfs = []\n",
    "\n",
    "    # Track the number of processed games\n",
    "    processed_games = 0\n",
    "\n",
    "    # Iterate over each game in the dataframe\n",
    "    for _, row in games.iterrows():\n",
    "        game_uuid = row['game_uuid']\n",
    "        pgn = row['pgn']\n",
    "\n",
    "        # Analyze the game and append the result to the list\n",
    "        game_df = analyze_chess_game(game_uuid, pgn, engine_path)\n",
    "        game_dfs.append(game_df)\n",
    "\n",
    "        # Increment and print the number of processed games\n",
    "        processed_games += 1\n",
    "        print(f\"Processed {processed_games} games\")\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    return pd.concat(game_dfs, ignore_index=True)\n",
    "\n",
    "# Call the function with the games DataFrame and get the result\n",
    "games_moves = analyze_multiple_games(games, engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into BigQuery table: chesscom-451104.staging.games_moves_20250225_0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up BigQuery client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../keyfile.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the BigQuery dataset\n",
    "dataset_id = 'chesscom-451104.staging'\n",
    "\n",
    "# Generate the table name with current date, hour, and minute\n",
    "date_suffix = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "table_id = f'{dataset_id}.games_moves_{date_suffix}'\n",
    "\n",
    "if not games_moves.empty:\n",
    "    # Load the DataFrame into BigQuery using pandas_gbq\n",
    "    to_gbq(games_moves, table_id, project_id='chesscom-451104', if_exists='replace') # DROP & CREATE data load (full)\n",
    "    print(f\"Data loaded into BigQuery table: {table_id}\")\n",
    "else:\n",
    "    print(\"The games DataFrame is empty. No data loaded into BigQuery.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
