{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bae6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Query executed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas_gbq import read_gbq\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up BigQuery client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../keyfile.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the BigQuery dataset and table names\n",
    "dataset_id = 'chesscom-451104.staging'\n",
    "table_games_prefix = 'games_infos_'  # Prefix for wildcard tables\n",
    "\n",
    "# Check if at least one table with the prefix \"games_\" exists\n",
    "def table_with_prefix_exists(client, dataset_id, prefix):\n",
    "    tables = client.list_tables(dataset_id)  # List all tables in the dataset\n",
    "    return any(table.table_id.startswith(prefix) for table in tables)\n",
    "\n",
    "# Check if games_moves_* tables exist\n",
    "if table_with_prefix_exists(client, dataset_id, table_games_prefix):\n",
    "    query = f\"\"\"\n",
    "    SELECT  \n",
    "        username, \n",
    "        MAX(archive_url) AS latest_url,\n",
    "        MAX(end_time) AS latest_end_time\n",
    "    FROM `{dataset_id}.{table_games_prefix}*`\n",
    "    GROUP BY 1\n",
    "    \"\"\"\n",
    "    username_import = read_gbq(query, project_id='chesscom-451104', dialect='standard')\n",
    "    print(\"Query executed successfully!\")\n",
    "else:\n",
    "    print(f\"No tables with the prefix '{table_games_prefix}' found.\")\n",
    "    username_import = pd.DataFrame()  # Return an empty DataFrame if no tables are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b6c2aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def get_filtered_archives(username, email):\n",
    "    headers = {'User-Agent': f'username: {username}, email: {email}'}\n",
    "    URL = f'https://api.chess.com/pub/player/{username}/games/archives'\n",
    "\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    archives = response.json()\n",
    "\n",
    "    if username_import.empty:\n",
    "        # If username_import is empty, return the original archives dictionary without filtering\n",
    "        return archives\n",
    "\n",
    "    # Extract the latest_url for the current username from the username_import dataframe\n",
    "    user_row = username_import[username_import['username'] == username]\n",
    "    if not user_row.empty:\n",
    "        latest_url = user_row.iloc[0]['latest_url']\n",
    "    else:\n",
    "        # Set a default value for latest_url if no match is found\n",
    "        latest_url = \"\"\n",
    "\n",
    "    # Filter the archive URLs to keep only those >= latest_url\n",
    "    filtered_archives = [\n",
    "        archive_url for archive_url in archives.get(\"archives\", [])\n",
    "        if latest_url == \"\" or archive_url >= latest_url\n",
    "    ]\n",
    "\n",
    "    # Update the archives dictionary with the filtered archives\n",
    "    archives['archives'] = filtered_archives\n",
    "\n",
    "    return archives\n",
    "\n",
    "def fetch_and_union_game_data(usernames, email):\n",
    "    # Initialize variables\n",
    "    all_game_data = []\n",
    "    current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Loop through each username\n",
    "    for username in usernames:\n",
    "        # Get the archives for the user\n",
    "        archives = get_filtered_archives(username, email)\n",
    "\n",
    "        user_row = username_import[username_import['username'] == username]\n",
    "        if not user_row.empty:\n",
    "            latest_end_time = datetime.strptime(user_row.iloc[0]['latest_end_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            latest_end_time = int(latest_end_time.timestamp())\n",
    "        else:\n",
    "            latest_end_time = 0\n",
    "\n",
    "        # Loop through each archive URL for the current user\n",
    "        for archive_url in archives.get(\"archives\", []):\n",
    "            # Fetch data for the current archive\n",
    "            response = requests.get(archive_url, headers={'User-Agent': f'username: {username}, email: {email}'})\n",
    "            archive_data = response.json()\n",
    "\n",
    "            # Extract game details into a list of dictionaries\n",
    "            game_data = [\n",
    "                {\n",
    "                    # Audit information\n",
    "                    \"archive_url\": archive_url,\n",
    "                    \"username\": username,\n",
    "                    \"bq_load_date\": current_timestamp,\n",
    "                    # General game information\n",
    "                    \"url\": game.get(\"url\", \"\"),\n",
    "                    \"pgn\": game.get(\"pgn\", \"\"),\n",
    "                    \"time_control\": game.get(\"time_control\", \"\"),\n",
    "                    \"end_time\": datetime.fromtimestamp(game.get(\"end_time\", 0)).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"rated\": game.get(\"rated\", False),\n",
    "                    \"tcn\": game.get(\"tcn\", \"\"),\n",
    "                    \"game_uuid\": game.get(\"uuid\", \"\"),\n",
    "                    \"initial_setup\": game.get(\"initial_setup\", \"\"),\n",
    "                    \"fen\": game.get(\"fen\", \"\"),\n",
    "                    \"time_class\": game.get(\"time_class\", \"\"),\n",
    "                    \"rules\": game.get(\"rules\", \"\"),\n",
    "                    # 'white' subfields\n",
    "                    \"white_username\": game.get(\"white\", {}).get(\"username\", \"\"),\n",
    "                    \"white_rating\": game.get(\"white\", {}).get(\"rating\", \"\"),\n",
    "                    \"white_result\": game.get(\"white\", {}).get(\"result\", \"\"),\n",
    "                    \"white_id\": game.get(\"white\", {}).get(\"@id\", \"\"),\n",
    "                    \"white_uuid\": game.get(\"white\", {}).get(\"uuid\", \"\"),\n",
    "                    # 'black' subfields\n",
    "                    \"black_username\": game.get(\"black\", {}).get(\"username\", \"\"),\n",
    "                    \"black_rating\": game.get(\"black\", {}).get(\"rating\", \"\"),\n",
    "                    \"black_result\": game.get(\"black\", {}).get(\"result\", \"\"),\n",
    "                    \"black_id\": game.get(\"black\", {}).get(\"@id\", \"\"),\n",
    "                    \"black_uuid\": game.get(\"black\", {}).get(\"uuid\", \"\"),\n",
    "                }\n",
    "                for game in archive_data.get(\"games\", [])\n",
    "                if game.get(\"end_time\", 0) > latest_end_time\n",
    "            ]\n",
    "            \n",
    "            all_game_data.extend(game_data)\n",
    "\n",
    "    df = pd.DataFrame(all_game_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "usernames = ['piwi100', 'Zundorn', 'leprechess', 'bgdu33']\n",
    "email = 'cassado01@gmail.com'\n",
    "games = fetch_and_union_game_data(usernames, email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into BigQuery successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up BigQuery client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../keyfile.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the BigQuery dataset and table name\n",
    "dataset_id = 'chesscom-451104.staging' \n",
    "\n",
    "# Generate the table name with current date, hour, and minute\n",
    "date_suffix = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "table_id = f'{dataset_id}.games_infos_{date_suffix}'\n",
    "\n",
    "if not games.empty:\n",
    "    # Load the DataFrame into BigQuery using pandas_gbq\n",
    "    to_gbq(games, table_id, project_id='chesscom-451104', if_exists='replace') # DROP & CREATE data load (full)\n",
    "    print(f\"Data loaded into BigQuery table: {table_id}\")\n",
    "else:\n",
    "    print(\"The games DataFrame is empty. No data loaded into BigQuery.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
